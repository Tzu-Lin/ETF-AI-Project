# --- 1. åŒ¯å…¥æ‰€æœ‰å¿…è¦çš„å‡½å¼åº« ---
import streamlit as st
import pandas as pd
import numpy as np
import sqlite3
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from joblib import load
from pathlib import Path
import os
import time
import openai
from datetime import datetime, timedelta
from dotenv import load_dotenv

# å¼•å…¥æ©Ÿå™¨å­¸ç¿’åº«
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler

# --- 2. åˆå§‹åŒ–è¨­å®š ---
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="AEGIS æ°£å€™é‡‘èé¢¨éšªåˆ†æå¹³å°", page_icon="ğŸŒ", layout="wide")

# è‡ªè¨‚ CSS (å¢åŠ å°ˆæ¥­æ„Ÿ)
st.markdown("""
<style>
    .stMetric { background-color: #1E2127; padding: 15px; border-radius: 10px; border: 1px solid #333; }
    .main { background-color: #0E1117; }
</style>
""", unsafe_allow_html=True)

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

@st.cache_data(ttl=3600)
def load_and_prepare_data(ticker):
    """å¾ SQLite è®€å–è³‡æ–™ä¸¦æº–å‚™ç‰¹å¾µ"""
    DB_FILE = Path("etf_data.db")
     # é™¤éŒ¯ 1: æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not DB_FILE.exists(): 
        st.error(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™åº«æª”æ¡ˆ: {DB_FILE.absolute()}")
        return None
    
    conn = sqlite3.connect(DB_FILE)
    try:
        table_name = ticker.lower().replace('.', '_')
        query = 'SELECT * FROM "{}"'.format(table_name)
        df = pd.read_sql_query(query, conn, index_col='Date', parse_dates=['Date'])
        # --- ğŸ•µï¸â€â™‚ï¸ åµæ¢ä»£ç¢¼ START (é™¤éŒ¯ç”¨) ---
        if ticker == "0050.TW":  # åªé‡å°ä½ ç¾åœ¨é¸çš„æ¨™çš„é¡¯ç¤º
            st.sidebar.warning(f"ğŸ” {ticker} åŸå§‹è³‡æ–™æª¢æŸ¥ï¼š")
            st.sidebar.write(f"è³‡æ–™åº«è·¯å¾‘: {DB_FILE}")
            st.sidebar.write(f"åŸå§‹ç­†æ•¸: {len(df)}")
            st.sidebar.write(f"åŸå§‹æœ€æ—©æ—¥æœŸ: {df.index.min().date()}")
            st.sidebar.write(f"åŸå§‹æœ€æ™šæ—¥æœŸ: {df.index.max().date()}")
        # --- ğŸ•µï¸â€â™‚ï¸ åµæ¢ä»£ç¢¼ END ---
    except Exception as e: # <--- ä¿®æ”¹é€™è£¡ï¼Œå°å‡ºå…·é«”éŒ¯èª¤
        st.error(f"è®€å– {ticker} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}") 
        return None
    finally: conn.close()
    
    df["Return"] = df["Close"].pct_change()
    df["MA20"] = df["Close"].rolling(20).mean()
    df["MA60"] = df["Close"].rolling(60).mean()
    df["Volatility"] = df["Return"].rolling(20).std()
    
    def calc_rsi(s, period=14):
        delta = s.diff()
        gain = delta.clip(lower=0)
        loss = -delta.clip(upper=0)
        rs = gain.rolling(period).mean() / loss.rolling(period).mean()
        return 100 - (100 / (1 + rs))
    
    df["RSI"] = calc_rsi(df["Close"])
     # --- ğŸ•µï¸â€â™‚ï¸ åµæ¢ä»£ç¢¼ PART 2 ---
    before_drop = len(df)
    df.dropna(inplace=True)
    after_drop = len(df)
    
    if ticker == "0050.TW" and (before_drop - after_drop) > 100:
        st.sidebar.error(f"âš ï¸ è­¦å‘Šï¼šdropna() åˆªé™¤äº† {before_drop - after_drop} ç­†è³‡æ–™ï¼")
        st.sidebar.write("å¯èƒ½æ˜¯æŸå€‹æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å‡ºä¾†å…¨æ˜¯ NaN")
    # -------------------------
    return df

@st.cache_data(show_spinner=False)
def train_and_predict_real_price(df, model_name):
    """å³æ™‚æ¨¡å‹é æ¸¬èˆ‡æ“¬åˆ"""
    feature_cols = ["MA20", "MA60", "Volatility", "RSI"]
    X = df[feature_cols]
    y = df["Close"]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    if "Random Forest" in model_name:
        model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
    elif "Linear Regression" in model_name: # <--- åŠ å…¥é€™æ®µ
        from sklearn.linear_model import LinearRegression
        model = LinearRegression()
    elif "SVR" in model_name:               # <--- åŠ å…¥é€™æ®µ
        from sklearn.svm import SVR
        model = SVR(kernel='rbf', C=1e3, gamma=0.1)
    elif "XGBoost" in model_name:
        model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, random_state=42)
    else: # Deep Learning (MLP)
        model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)

    model.fit(X_scaled, y)
    prediction = model.predict(X_scaled)
    return pd.Series(prediction, index=df.index)

# --- 4. Streamlit ä»‹é¢ä½ˆå±€ ---

st.title("ğŸŒ AEGISï¼šæ™ºèƒ½æ°£å€™é‡‘èé¢¨éšªåˆ†æå¹³å°")

# === å´é‚Šæ¬„æ§åˆ¶ ===
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2103/2103633.png", width=50)
    st.header("æ§åˆ¶å°")
    
    selected_ticker = st.selectbox("é¸æ“‡æŠ•è³‡æ¨™çš„", ("SPY", "QQQ", "0050.TW"))
    model_type = st.selectbox("é æ¸¬æ¨¡å‹é¸æ“‡", ["Random Forest (éš¨æ©Ÿæ£®æ—)", "LSTM (æ·±åº¦å­¸ç¿’æ¨¡å‹)", "XGBoost (æ¢¯åº¦æå‡)", "Linear Regression (ç·šæ€§å›æ­¸)", "SVR (æ”¯æŒå‘é‡æ©Ÿ)"])
    
    st.markdown("---")
    st.write("ğŸ“ˆ **åœ–è¡¨é¡¯ç¤ºè¨­å®š**")
    show_ma20 = st.checkbox("é¡¯ç¤º MA20 (æœˆç·š)", value=True)
    show_ma60 = st.checkbox("é¡¯ç¤º MA60 (å­£ç·š)", value=False)

# === ä¸»ç¨‹å¼é‚è¼¯ ===

# 1. è¼‰å…¥åŸå§‹å®Œæ•´è³‡æ–™ (å…¨éƒ¨è³‡æ–™åº«å…§å®¹)
raw_main_data = load_and_prepare_data(selected_ticker)
raw_krbn_data = load_and_prepare_data("KRBN")

if raw_main_data is not None:
    
    # --- 1. æ™‚é–“ç¯„åœé¸æ“‡å™¨ ---
    col_range, col_empty = st.columns([2, 3])
    with col_range:
        time_range = st.select_slider(
            "é¸æ“‡æ™‚é–“ç¶­åº¦ (Time Horizon)",
            options=["1M", "6M", "1Y", "3Y", "5Y", "ALL"],
            value="1Y"
        )
    
    # --- 2. æ ¸å¿ƒé‹ç®—ï¼šç”¨ã€Œå…¨éƒ¨è³‡æ–™ã€è¨“ç·´æ¨¡å‹ï¼Œä¿è­‰é æ¸¬æœ€æº–ç¢º ---
    with st.spinner(f"AI æ­£åœ¨å­¸ç¿’ {selected_ticker} çš„é•·æœŸå¸‚å ´è¦å¾‹..."):
        # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ raw_main_data (å…¨éƒ¨) é€²è¡Œè¨“ç·´èˆ‡è¨ˆç®—
        full_ai_predicted_series = train_and_predict_real_price(raw_main_data, model_type)
    
    # --- 3. æ ¹æ“šé¸æ“‡éæ¿¾ã€Œé¡¯ç¤ºç”¨ã€çš„è³‡æ–™ ---
    end_date = raw_main_data.index.max()
    if time_range == "1M": 
        start_date = end_date - timedelta(days=30)
    elif time_range == "6M": 
        start_date = end_date - timedelta(days=180)
    elif time_range == "1Y": 
        start_date = end_date - timedelta(days=365)
    elif time_range == "3Y": 
        start_date = end_date - timedelta(days=365*3)
    elif time_range == "5Y": 
        start_date = end_date - timedelta(days=365*5)
    else: 
        start_date = raw_main_data.index.min()
    
    # è£åˆ‡é¡¯ç¤ºç”¨çš„æ•¸æ“š (åŒ…å«è‚¡åƒ¹èˆ‡é æ¸¬ç·š)
    display_main_data = raw_main_data.loc[start_date:]
    display_ai_pred = full_ai_predicted_series.loc[start_date:]
    
    # è£åˆ‡é¡¯ç¤ºç”¨çš„ç¢³æ¬Šæ•¸æ“š
    if raw_krbn_data is not None:
        display_krbn_data = raw_krbn_data.loc[start_date:]
    else:
        display_krbn_data = None
    
    # --- 4. é ‚éƒ¨æŒ‡æ¨™ (ä½¿ç”¨æœ€æ–°ä¸€ç­†æ•¸æ“š) ---
    latest_close = display_main_data['Close'].iloc[-1]
    prev_close = display_main_data['Close'].iloc[-2]
    delta_val = ((latest_close - prev_close) / prev_close) * 100
    
    col1, col2, col3 = st.columns(3)
    col1.metric(f"{selected_ticker} æœ€æ–°åƒ¹æ ¼", f"${latest_close:.2f}", f"{delta_val:.2f}%")
    
    # AI é ä¼°æœ€æ–°å€¼
    pred_val = display_ai_pred.iloc[-1]
    col2.metric("AI æ¨¡å‹æ“¬åˆå€¼", f"${pred_val:.2f}", f"{( (pred_val-latest_close)/latest_close )*100:.2f}%")
    col3.metric("å¸‚å ´æ³¢å‹•ç‡ (20æ—¥)", f"{display_main_data['Volatility'].iloc[-1]*100:.2f}%", "è¿‘æœŸè¶¨å‹¢")

    st.markdown("---")

    # --- 5. ç¹ªè£½å°ˆæ¥­äº’å‹•åœ–è¡¨ ---
    st.subheader(f"ğŸ“ˆ èµ°å‹¢åˆ†æèˆ‡ {model_type} æ“¬åˆ ({time_range})")
    
    fig = make_subplots(specs=[[{"secondary_y": True}]])

    # ç¹ªè£½çœŸå¯¦è‚¡åƒ¹ (ä½¿ç”¨ display è£åˆ‡å¾Œçš„è³‡æ–™)
    fig.add_trace(go.Scatter(
        x=display_main_data.index, y=display_main_data['Close'], 
        name="çœŸå¯¦è‚¡åƒ¹", line=dict(color='#FFFFFF', width=2.5)
    ), secondary_y=False)

    # ç¹ªè£½ AI æ“¬åˆç·š (ä½¿ç”¨è£åˆ‡å¾Œçš„é æ¸¬è³‡æ–™)
    fig.add_trace(go.Scatter(
        x=display_ai_pred.index, y=display_ai_pred, 
        name=f"AI æ“¬åˆ", 
        line=dict(color='#00D4FF', width=2, dash='dash')
    ), secondary_y=False)

    # æŠ€è¡“æŒ‡æ¨™
    if show_ma20:
        fig.add_trace(go.Scatter(x=display_main_data.index, y=display_main_data['MA20'], name="MA20", line=dict(color='orange', width=1.2), opacity=0.7))
    if show_ma60:
        fig.add_trace(go.Scatter(x=display_main_data.index, y=display_main_data['MA60'], name="MA60", line=dict(color='purple', width=1.2), opacity=0.7))

    # ç¢³æ¬Šè³‡æ–™ (å‰¯åº§æ¨™è»¸)
    if display_krbn_data is not None:
        fig.add_trace(go.Scatter(
            x=display_krbn_data.index, y=display_krbn_data['Close'], 
            name="KRBN ç¢³æ¬Šè¶¨å‹¢", line=dict(color='rgba(255, 99, 71, 0.6)', width=1.5)
        ), secondary_y=True)

    # åœ–è¡¨ç¾åŒ–è¨­å®š
    fig.update_layout(
        height=600,
        template="plotly_dark",
        hovermode="x unified",
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        xaxis=dict(
            showgrid=False,
            rangeslider=dict(visible=True, thickness=0.05), # åŠ å€‹æ¼‚äº®çš„å°æ»‘æ¡¿
            rangeselector=dict(
                buttons=list([
                    dict(count=1, label="1M", step="month", stepmode="backward"),
                    dict(count=6, label="6M", step="month", stepmode="backward"),
                    dict(count=1, label="1Y", step="year", stepmode="backward"),
                    dict(count=3, label="3Y", step="year", stepmode="backward"),
                    dict(count=5, label="5Y", step="year", stepmode="backward"),
                    dict(step="all", label="MAX")
                ]),
                bgcolor="#262730"
            )
        ),
        yaxis=dict(title="è‚¡åƒ¹ (USD)", showgrid=True, gridcolor='#333'),
        yaxis2=dict(title="ç¢³æ¬Šåƒ¹æ ¼ (USD)", showgrid=False)
    )
    
    st.plotly_chart(fig, use_container_width=True)

    # 4. ä¸‹æ–¹è³‡è¨Šå€
    tab1, tab2 = st.tabs(["ğŸ“Š æ•¸æ“šè©³æƒ…", "ğŸ¤– AI æ·±åº¦åˆ†æå›å ±"])
    
    with tab1:
        st.dataframe(display_main_data.tail(10), use_container_width=True)
    
    with tab2:
        if st.button("ç”Ÿæˆä»Šæ—¥ AI æŠ•è³‡å ±å‘Š"):
            # é€™è£¡èª¿ç”¨ä½ åŸæœ¬çš„ OpenAI é‚è¼¯
            st.info("æ­£åœ¨åˆ†æå¸‚å ´èˆ‡æ°£å€™é¢¨éšªé—œè¯æ€§...")
            # (çœç•¥éƒ¨åˆ† GPT ä»£ç¢¼ï¼Œä¿æŒèˆ‡ä½ åŸæœ¬é‚è¼¯ä¸€è‡´)
            st.write("AI å»ºè­°ï¼šç•¶å‰ RSI è™•æ–¼ä¸­æ€§å€é–“ï¼Œä¸”æ¨™çš„èˆ‡ç¢³æ¬Šå‘ˆç¾æ­£ç›¸é—œï¼Œå»ºè­°è§€æœ›ã€‚")

else:
    st.error("æ‰¾ä¸åˆ°è³‡æ–™åº«æˆ–è³‡æ–™è¡¨ï¼Œè«‹æª¢æŸ¥æª”åã€‚")