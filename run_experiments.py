# run_experiments.py (ã€åµéŒ¯ç‰ˆã€‘)

import sqlite3
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# å¾ models.py å°å…¥æ‰€æœ‰æ¨¡å‹é¡åˆ¥
from models import (
    RandomForestModel, 
    SingleLayerLSTM, 
    DoubleLayerLSTM, 
    SingleLayerBiLSTM, 
    DoubleLayerBiLSTM
)

# --- å‡½å¼å®šç¾©å€ ---

def load_data_from_sqlite(ticker, db_path='etf_data.db'):
    """å¾ SQLite è³‡æ–™åº«è®€å–ç‰¹å®š ETF çš„è³‡æ–™"""
    print(f"\n{'='*20} æ­£åœ¨è™•ç† {ticker} {'='*20}")
    conn = sqlite3.connect(db_path)
    table_name = ticker.lower().replace('.tw', '_tw')
    try:
        df = pd.read_sql_query(f'SELECT * FROM "{table_name}"', conn)
        conn.close()
        # ã€åµéŒ¯é» 1ã€‘: ç¢ºèªåŸå§‹è®€å–ç­†æ•¸
        print(f"ã€åµéŒ¯ 1ã€‘: å¾è³‡æ–™åº«æˆåŠŸè®€å– {table_name}ï¼ŒåŸå§‹ç­†æ•¸: {len(df)}")
        if df.empty:
            print("ã€è­¦å‘Šã€‘: è®€å–åˆ°çš„ DataFrame ç‚ºç©ºï¼")
            return None
            
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        return df
    except Exception as e:
        print(f"è®€å–è¡¨æ ¼ {table_name} å¤±æ•—: {e}")
        conn.close()
        return None

def feature_engineering(df):
    """åŸ·è¡Œç‰¹å¾µå·¥ç¨‹"""
    print("æ­£åœ¨é€²è¡Œç‰¹å¾µå·¥ç¨‹...")
    df['Return'] = df['Close'].pct_change()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['MA60'] = df['Close'].rolling(window=60).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))

    df['Target'] = (df['Return'].shift(-1) > 0).astype(int)
    
    # ã€åµéŒ¯é» 2ã€‘: æª¢æŸ¥ dropna å‰çš„ç©ºå€¼æ•¸é‡
    print(f"ã€åµéŒ¯ 2ã€‘: åŸ·è¡Œ dropna ä¹‹å‰ï¼Œå„æ¬„ä½ç©ºå€¼(NaN)æ•¸é‡:\n{df.isnull().sum()}")
    
    df.dropna(inplace=True)
    
    # ã€åµéŒ¯é» 3ã€‘: ç¢ºèª dropna å¾Œçš„å‰©é¤˜ç­†æ•¸ (æœ€é—œéµï¼)
    print(f"ã€åµéŒ¯ 3ã€‘: åŸ·è¡Œ dropna ä¹‹å¾Œï¼Œå‰©é¤˜çš„è³‡æ–™ç­†æ•¸: {len(df)}")
    
    if df.empty:
        print("ã€åš´é‡éŒ¯èª¤ã€‘: dropna å¾Œæ²’æœ‰ä»»ä½•æ•¸æ“šå‰©é¤˜ï¼ç„¡æ³•ç¹¼çºŒè™•ç†ã€‚")
        return None, None # å›å‚³ç©ºå€¼

    features = ['Return', 'MA20', 'MA60', 'RSI']
    X = df[features]
    y = df['Target']
    
    return X, y

# ... (create_sequences å‡½å¼ä¸è®Š) ...
def create_sequences(X, y, time_steps=30):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X[i:(i + time_steps)])
        ys.append(y[i + time_steps])
    return np.array(Xs), np.array(ys)

# --- ä¸»ç¨‹å¼åŸ·è¡Œå€ ---

if __name__ == "__main__":
    
    TICKERS = ["SPY", "QQQ", "0050.TW"]
    TIME_STEPS = 30
    all_results = []

    for ticker in TICKERS:
        raw_df = load_data_from_sqlite(ticker)
        if raw_df is None:
            continue
            
        X_raw, y_raw = feature_engineering(raw_df)

        # ã€åµéŒ¯é» 4ã€‘: æª¢æŸ¥ç‰¹å¾µå·¥ç¨‹çš„è¼¸å‡º
        if X_raw is None or y_raw is None:
            print(f"--- å› ç‚º {ticker} çš„æ•¸æ“šåœ¨ç‰¹å¾µå·¥ç¨‹å¾Œç‚ºç©ºï¼Œå·²è·³é ---")
            continue # è·³åˆ°ä¸‹ä¸€å€‹ Ticker

        print(f"ã€åµéŒ¯ 4ã€‘: ç‰¹å¾µå·¥ç¨‹æˆåŠŸï¼Œæº–å‚™åˆ‡å‰²è³‡æ–™ã€‚X_raw shape: {X_raw.shape}, y_raw shape: {y_raw.shape}")

        # --- è³‡æ–™æº–å‚™èˆ‡åˆ‡å‰² ---
        split_point = int(len(X_raw) * 0.8)

        X_train_raw, X_test_raw = X_raw[:split_point], X_raw[split_point:]
        y_train_raw, y_test_raw = y_raw[:split_point], y_raw[split_point:]

        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_raw)
        X_test_scaled = scaler.transform(X_test_raw)

        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_raw.values, TIME_STEPS)
        X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_raw.values, TIME_STEPS)
        
        X_train_rf = X_train_scaled[TIME_STEPS:]
        y_train_rf = y_train_raw.values[TIME_STEPS:]
        X_test_rf = X_test_scaled[TIME_STEPS:]
        y_test_rf = y_test_raw.values[TIME_STEPS:]

        input_shape_seq = (X_train_seq.shape[1], X_train_seq.shape[2])
        
        models_to_run = {
            "RandomForest": {"model": RandomForestModel(n_estimators=100),"X_train": X_train_rf, "y_train": y_train_rf,"X_test": X_test_rf, "y_test": y_test_rf},
            "SingleLayerLSTM": {"model": SingleLayerLSTM(input_shape=input_shape_seq),"X_train": X_train_seq, "y_train": y_train_seq,"X_test": X_test_seq, "y_test": y_test_seq},
            "DoubleLayerLSTM": {"model": DoubleLayerLSTM(input_shape=input_shape_seq),"X_train": X_train_seq, "y_train": y_train_seq,"X_test": X_test_seq, "y_test": y_test_seq},
            "SingleLayerBiLSTM": {"model": SingleLayerBiLSTM(input_shape=input_shape_seq),"X_train": X_train_seq, "y_train": y_train_seq,"X_test": X_test_seq, "y_test": y_test_seq},
            "DoubleLayerBiLSTM": {"model": DoubleLayerBiLSTM(input_shape=input_shape_seq),"X_train": X_train_seq, "y_train": y_train_seq,"X_test": X_test_seq, "y_test": y_test_seq}
        }
        
        for name, config in models_to_run.items():
            print(f"--- æ­£åœ¨ç‚º {ticker} è¨“ç·´ {name} ---")
            model = config["model"]
            xtrain, ytrain = config["X_train"], config["y_train"]
            xtest, ytest = config["X_test"], config["y_test"]
            model.train(xtrain, ytrain)
            predictions, prob_up, prob_down = model.predict(xtest)
            acc = accuracy_score(ytest, predictions)
            precision = precision_score(ytest, predictions, zero_division=0)
            recall = recall_score(ytest, predictions, zero_division=0)
            f1 = f1_score(ytest, predictions, zero_division=0)
            tomorrow_up_prob = np.ravel(prob_up)[-1]
            tomorrow_down_prob = np.ravel(prob_down)[-1]
            all_results.append({"Ticker": ticker, "Model": name, "Accuracy": acc,"Precision": precision,"Recall": recall,"F1-Score": f1, "Tomorrow_Up_Prob": tomorrow_up_prob,"Tomorrow_Down_Prob": tomorrow_down_prob})
            print(f"{name} -> Accuracy: {acc:.4f}, F1-Score: {f1:.4f} | æ˜æ—¥é æ¸¬: ä¸Šæ¼²æ©Ÿç‡ {tomorrow_up_prob:.2%}")

    results_df = pd.DataFrame(all_results, columns=['Ticker', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Tomorrow_Up_Prob', 'Tomorrow_Down_Prob'])
    results_df.to_csv("experiment_results.csv", index=False)
    print("\nğŸ‰ æ‰€æœ‰å¯¦é©—å®Œæˆï¼çµæœå·²å„²å­˜è‡³ experiment_results.csv")
    print(results_df)