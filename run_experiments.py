# run_experiments.py (é‡æ§‹å‡ç´šç‰ˆ)

import sqlite3
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# å¾ models.py å°å…¥æ‰€æœ‰æ¨¡å‹é¡åˆ¥
from models import (
    RandomForestModel, 
    SingleLayerLSTM, 
    DoubleLayerLSTM, 
    SingleLayerBiLSTM, 
    DoubleLayerBiLSTM
)

# --- å‡½å¼å®šç¾©å€ (èˆ‡æ‚¨ç‰ˆæœ¬ç›¸åŒï¼Œç¨ä½œå„ªåŒ–) ---

def load_data_from_sqlite(ticker, db_path='etf_data.db'):
    """å¾ SQLite è³‡æ–™åº«è®€å–ç‰¹å®š ETF çš„è³‡æ–™"""
    print(f"\n{'='*20} æ­£åœ¨è™•ç† {ticker} {'='*20}")
    conn = sqlite3.connect(db_path)
    table_name = ticker.lower().replace('.tw', '_tw')
    try:
        df = pd.read_sql_query(f'SELECT * FROM "{table_name}"', conn)
        conn.close()
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        print(f"è³‡æ–™è®€å–å®Œç•¢ï¼Œå…± {len(df)} ç­†ã€‚")
        return df
    except Exception as e:
        print(f"è®€å–è¡¨æ ¼ {table_name} å¤±æ•—: {e}")
        conn.close()
        return None

def feature_engineering(df):
    """åŸ·è¡Œç‰¹å¾µå·¥ç¨‹"""
    print("æ­£åœ¨é€²è¡Œç‰¹å¾µå·¥ç¨‹...")
    df['Return'] = df['Close'].pct_change()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['MA60'] = df['Close'].rolling(window=60).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))

    df['Target'] = (df['Return'].shift(-1) > 0).astype(int)
    df.dropna(inplace=True)
    
    features = ['Return', 'MA20', 'MA60', 'RSI']
    X = df[features]
    y = df['Target']
    
    return X, y

def create_sequences(X, y, time_steps=30):
    """ç‚ºæ·±åº¦å­¸ç¿’æ¨¡å‹å‰µå»ºæ™‚é–“åºåˆ—æ•¸æ“šé›†"""
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X[i:(i + time_steps)])
        ys.append(y[i + time_steps])
    return np.array(Xs), np.array(ys)

# --- ä¸»ç¨‹å¼åŸ·è¡Œå€ ---

if __name__ == "__main__":
    
    TICKERS = ["SPY", "QQQ", "0050.TW"]
    TIME_STEPS = 30 # æ»‘å‹•çª—å£å¤§å°
    all_results = []

    for ticker in TICKERS:
        raw_df = load_data_from_sqlite(ticker)
        if raw_df is None:
            continue
            
        X_raw, y_raw = feature_engineering(raw_df)

        # --- è³‡æ–™æº–å‚™èˆ‡åˆ‡å‰² ---
        # 1. å…ˆåˆ‡å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†ï¼Œé¿å…æ•¸æ“šæ´©æ¼
        split_point = int(len(X_raw) * 0.8)
        X_train_raw, X_test_raw = X_raw[:split_point], X_raw[split_point:]
        y_train_raw, y_test_raw = y_raw[:split_point], y_raw[split_point:]

        # 2. ç”¨è¨“ç·´é›†çš„åƒæ•¸ä¾†æ¨™æº–åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_raw)
        X_test_scaled = scaler.transform(X_test_raw)

        # 3. å‰µå»ºçµ¦æ·±åº¦å­¸ç¿’æ¨¡å‹çš„ 3D æ™‚åºæ•¸æ“š
        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_raw.values, TIME_STEPS)
        X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_raw.values, TIME_STEPS)
        
        # å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ä¸èƒ½ä½¿ç”¨ 3D æ•¸æ“šï¼Œæˆ‘å€‘éœ€è¦æŠŠå®ƒ"å£“å¹³"
        # æˆ‘å€‘å–æ¯å€‹åºåˆ—çš„æœ€å¾Œä¸€å¤©ä½œç‚º RandomForest çš„è¼¸å…¥
        X_train_rf = X_train_scaled[TIME_STEPS:]
        y_train_rf = y_train_raw.values[TIME_STEPS:]
        X_test_rf = X_test_scaled[TIME_STEPS:]
        y_test_rf = y_test_raw.values[TIME_STEPS:]

        # --- æ¨¡å‹é…ç½®å­—å…¸ ---
        # åœ¨é€™è£¡å®šç¾©æ‰€æœ‰ä½ æƒ³è·‘çš„æ¨¡å‹å’Œå®ƒå€‘éœ€è¦çš„æ•¸æ“š
        input_shape_seq = (X_train_seq.shape[1], X_train_seq.shape[2])
        
        models_to_run = {
            "RandomForest": {
                "model": RandomForestModel(n_estimators=100),
                "X_train": X_train_rf, "y_train": y_train_rf,
                "X_test": X_test_rf, "y_test": y_test_rf
            },
            "SingleLayerLSTM": {
                "model": SingleLayerLSTM(input_shape=input_shape_seq),
                "X_train": X_train_seq, "y_train": y_train_seq,
                "X_test": X_test_seq, "y_test": y_test_seq
            },
            "DoubleLayerLSTM": {
                "model": DoubleLayerLSTM(input_shape=input_shape_seq),
                "X_train": X_train_seq, "y_train": y_train_seq,
                "X_test": X_test_seq, "y_test": y_test_seq
            },
            "SingleLayerBiLSTM": {
                "model": SingleLayerBiLSTM(input_shape=input_shape_seq),
                "X_train": X_train_seq, "y_train": y_train_seq,
                "X_test": X_test_seq, "y_test": y_test_seq
            },
            "DoubleLayerBiLSTM": {
                "model": DoubleLayerBiLSTM(input_shape=input_shape_seq),
                "X_train": X_train_seq, "y_train": y_train_seq,
                "X_test": X_test_seq, "y_test": y_test_seq
            }
        }
        
        # --- è‡ªå‹•åŒ–åŸ·è¡Œè¿´åœˆ ---
        for name, config in models_to_run.items():
            print(f"--- æ­£åœ¨ç‚º {ticker} è¨“ç·´ {name} ---")
            
            # å¾é…ç½®ä¸­ç²å–æ¨¡å‹å’Œå°æ‡‰çš„æ•¸æ“š
            model = config["model"]
            xtrain, ytrain = config["X_train"], config["y_train"]
            xtest, ytest = config["X_test"], config["y_test"]
            
            # çµ±ä¸€çš„è¨“ç·´å’Œé æ¸¬æµç¨‹
            model.train(xtrain, ytrain)
            pred, prob_up, prob_down = model.predict(xtest)
            
            acc = accuracy_score(ytest, pred)
            
            # ç²å–å°"æ˜å¤©"çš„é æ¸¬æ©Ÿç‡ (æ¸¬è©¦é›†çš„æœ€å¾Œä¸€ç­†)
            tomorrow_up_prob = np.ravel(prob_up)[-1]
            tomorrow_down_prob = np.ravel(prob_down)[-1]

            all_results.append({
                "Ticker": ticker, 
                "Model": name, 
                "Accuracy": acc,
                "Tomorrow_Up_Prob": tomorrow_up_prob,
                "Tomorrow_Down_Prob": tomorrow_down_prob
            })
            print(f"{name} æº–ç¢ºç‡: {acc:.4f} | æ˜æ—¥é æ¸¬: ä¸Šæ¼²æ©Ÿç‡ {tomorrow_up_prob:.2%}, ä¸‹è·Œæ©Ÿç‡ {tomorrow_down_prob:.2%}")

    # --- å„²å­˜æœ€çµ‚çµæœ ---
    results_df = pd.DataFrame(all_results)
    results_df.to_csv("experiment_results.csv", index=False)
    print("\nğŸ‰ æ‰€æœ‰å¯¦é©—å®Œæˆï¼çµæœå·²å„²å­˜è‡³ experiment_results.csv")
    print(results_df)